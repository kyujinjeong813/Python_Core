{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "import numpy as np\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications import resnet50\n",
    "\n",
    "filename = 'banana.jpg'\n",
    "original = load_img(filename, target_size=(224, 224))\n",
    "print('PLT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DC GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.layers import Activation, Dense, Input\n",
    "from keras.layers import Conv2D, Flatten\n",
    "from keras.layers import Reshape, Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(inputs, image_size):\n",
    "    image_resize = image_size // 4 #로 나눈 몫....????\n",
    "    kernel_size = 5\n",
    "    layer_filters = [128, 64, 32, 1]\n",
    "    \n",
    "    x = Dense(image_resize * image_resize * layer_filters[0])(inputs)\n",
    "    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n",
    "    \n",
    "    for filters in layer_filters:\n",
    "        if filters > layer_filters[-2]:\n",
    "            strides = 2\n",
    "        else:\n",
    "            strides = 1\n",
    "        x = BatchNormalizarion()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2DTranspose(filters=filters, kernel_size=kernel_size,\n",
    "                           strides=strides, padding='same')(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    generator = Model(inputs, x, name='generator')\n",
    "    return generator\n",
    "# 코드가 특이하고만, 옛날 방식인가.. 흠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_discriminator(inputs):\n",
    "    kernel_size = 5\n",
    "    layer_filters = [32, 64, 128, 256]\n",
    "    \n",
    "    x = inputs\n",
    "    for filters in layer_filters:\n",
    "        if filters == layer_filters[-1]:\n",
    "            strides = 1\n",
    "        else:\n",
    "            strides = 2\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                  strides=strides, padding='same')(x)\n",
    "        \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    discriminator = Model(inputs, x, name='discriminator')\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(models, x_train, params):\n",
    "    generator, discriminator, adversarial = models\n",
    "    batch_size, latent_size, train_steps, model_name = params\n",
    "    save_interval = 500\n",
    "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\n",
    "    train_size = x_train.shape[0]\n",
    "    for i in range(train_steps):\n",
    "        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n",
    "        real_images = x_train[rand_indexes]\n",
    "        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
    "        fake_images = generator.predict(noise)\n",
    "        x = np.concatenate((real_images, fake_images))\n",
    "        y = np.ones([2*batch_size, 1])\n",
    "        y[batch_size:, :] = 0.0\n",
    "        loss, acc = discriminator.train_on_batch(x, y)\n",
    "        log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n",
    "        \n",
    "        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
    "        y = np.ones([batch_size, 1])\n",
    "        loss, acc = adversarial.train_on_batch(noise, y)\n",
    "        log = \"%s [ adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n",
    "        print(log)\n",
    "        if (i+1) % save_interval == 0:\n",
    "            plot_images(generator, noise_input, show=False, step=(i+1),\n",
    "                       model_name = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(generator, nooise_input, show=False, step=0,\n",
    "               model_name='gan'):\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
    "    images = generator.predict(noise_input)\n",
    "    plt.figure(figsize=(2.2, 2.2))\n",
    "    num_images = images.shape[0]\n",
    "    image_size = images.shape[1]\n",
    "    rows = int(math.sqrt(noise_input.shape[0]))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(rows, rows, i + 1)\n",
    "        image = np.reshape(images[i], [image_size, image_size])\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(filename)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_models():\n",
    "    (x_train, _), (_, _) = mnist.load_data()\n",
    "    image_size = x_train.shape[1]\n",
    "    x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    \n",
    "    model_name = 'dcgan_mnist'\n",
    "    latent_size = 100\n",
    "    batch_size = 64\n",
    "    train_steps = 40000\n",
    "    lr = 23-4\n",
    "    decay = 6e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pix2pix\n",
    "https://www.tensorflow.org/tutorials/generative/pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "# !pip install -q -U tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_URL = 'https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/facades.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/facades.tar.gz\n",
      "30171136/30168306 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_zip = tf.keras.utils.get_file('facades.tar.gz', origin=_URL, extract=True)\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'facades/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 400\n",
    "batch_size = 1\n",
    "img_width = 256\n",
    "img_height = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(image_file):\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    \n",
    "    w = tf.shape(image)[1]\n",
    "    w = w // 2\n",
    "    real_image = image[:, :w, :]\n",
    "    input_image = image[:, w:, :]\n",
    "    \n",
    "    input_image = tf.cast(input_image, tf.float32)\n",
    "    real_image = tf.cast(real_image, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
