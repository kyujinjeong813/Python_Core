{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kor_bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCJYxm8pKRpX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "4aecb570-6924-4da4-f039-1a7f6bb4dad8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Feb 14 05:26:25 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b24P7R1YkAE",
        "colab_type": "code",
        "outputId": "64e1bff1-fd0c-44d7-cf62-65975db48a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "!pip install gluonnlp"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gluonnlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/29/c7dffbfc39f8dd8bb9314df7aaf92a67f6c7826ed35d546c8fa63d6e5925/gluonnlp-0.8.3.tar.gz (236kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 28.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 33.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 35.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 39.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 51kB 42.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 45.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71kB 45.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 46.7MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92kB 47.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 102kB 49.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112kB 49.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 122kB 49.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133kB 49.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 143kB 49.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153kB 49.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 163kB 49.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174kB 49.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184kB 49.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194kB 49.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 204kB 49.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215kB 49.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 225kB 49.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235kB 49.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 49.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (1.17.5)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.8.3-cp36-none-any.whl size=293540 sha256=ac764f9e6477aedd3462ddef7762637068e48ebacc9fc819770e24cbd754d583\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/6e/32/521aa84da7f9ee725d3c9be0b5e0d771df659bf25da5929f6c\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.8.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZiYU4IyZVsm",
        "colab_type": "code",
        "outputId": "af612197-7c03-4c93-d16b-65ac0ea8344d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "!pip install mxnet-cu101"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet-cu101\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\",)': /packages/57/aa/474e97edaa2064c4e57dfb5685290ffc188592878c8bc58a1dca770872b5/mxnet_cu101-1.5.1.post0-py2.py3-none-manylinux1_x86_64.whl\u001b[0m\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\",)': /packages/57/aa/474e97edaa2064c4e57dfb5685290ffc188592878c8bc58a1dca770872b5/mxnet_cu101-1.5.1.post0-py2.py3-none-manylinux1_x86_64.whl\u001b[0m\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\",)': /packages/57/aa/474e97edaa2064c4e57dfb5685290ffc188592878c8bc58a1dca770872b5/mxnet_cu101-1.5.1.post0-py2.py3-none-manylinux1_x86_64.whl\u001b[0m\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/aa/474e97edaa2064c4e57dfb5685290ffc188592878c8bc58a1dca770872b5/mxnet_cu101-1.5.1.post0-py2.py3-none-manylinux1_x86_64.whl (551.3MB)\n",
            "\u001b[K     |███████████▏                    | 192.5MB 101.4MB/s eta 0:00:04"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrP92KL6XuVx",
        "colab_type": "code",
        "outputId": "a8ff3638-cddd-4fe2-847f-460909b04413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from mxnet.gluon import nn, rnn\n",
        "from mxnet import gluon, autograd\n",
        "import gluonnlp as nlp\n",
        "from mxnet import nd \n",
        "import mxnet as mx\n",
        "import time\n",
        "import itertools\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7b2282cd4ddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgluon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgluon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgluonnlp\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mxnet'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iePEqt8sYEjb",
        "colab_type": "code",
        "outputId": "c6018cdd-9bca-4000-8a2f-453401d6d73e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        }
      },
      "source": [
        "ctx = mx.gpu()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-27c84b34634e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'mx' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03AvLHJMYElS",
        "colab_type": "code",
        "outputId": "a440d514-7044-4a9b-c216-630aa446921c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "bert_base, vocabulary = nlp.model.get_model('bert_12_768_12',\n",
        "                                             dataset_name='wiki_multilingual_cased',\n",
        "                                             pretrained=True, ctx=ctx, use_pooler=True,\n",
        "                                             use_decoder=False, use_classifier=False)\n",
        "#print(bert_base)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2f388ef45673>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m bert_base, vocabulary = nlp.model.get_model('bert_12_768_12',\n\u001b[0m\u001b[1;32m      2\u001b[0m                                              \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wiki_multilingual_cased'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                              \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_pooler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                              use_decoder=False, use_classifier=False)\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(bert_base)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpvtY--5YEnC",
        "colab_type": "code",
        "outputId": "f5019da3-15b7-4692-8b33-ff60e16995a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "ds = gluon.data.SimpleDataset([['나 보기가 역겨워', '김소월']])\n",
        "\n",
        "tok = nlp.data.BERTTokenizer(vocab=vocabulary, lower=False)\n",
        "\n",
        "trans = nlp.data.BERTSentenceTransform(tok, max_seq_length=10)\n",
        "\n",
        "list(ds.transform(trans))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0d4a0afe4fdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgluon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSimpleDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'나 보기가 역겨워'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'김소월'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBERTTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBERTSentenceTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vocabulary' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSki94N5YEos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#데이터는 https://github.com/e9t/nsmc 다운받는다. \n",
        "dataset_train = nlp.data.TSVDataset(\"ratings_train.txt\", field_indices=[1,2], num_discard_samples=1)\n",
        "dataset_test = nlp.data.TSVDataset(\"ratings_test.txt\", field_indices=[1,2], num_discard_samples=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IiESY6kZBY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERTDataset(mx.gluon.data.Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "        sent_dataset = gluon.data.SimpleDataset([[\n",
        "            i[sent_idx],\n",
        "        ] for i in dataset])\n",
        "        self.sentences = sent_dataset.transform(transform)\n",
        "        self.labels = gluon.data.SimpleDataset(\n",
        "            [np.array(np.int32(i[label_idx])) for i in dataset])\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn4jGINFZBam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=False)\n",
        "max_len = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8tMe3juZBd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train = BERTDataset(dataset_train, 0, 1, bert_tokenizer, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test, 0, 1, bert_tokenizer, max_len, True, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIN0OX3MZBft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERTClassifier(nn.Block):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 num_classes=2,\n",
        "                 dropout=None,\n",
        "                 prefix=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__(prefix=prefix, params=params)\n",
        "        self.bert = bert\n",
        "        with self.name_scope():\n",
        "            self.classifier = nn.HybridSequential(prefix=prefix)\n",
        "            if dropout:\n",
        "                self.classifier.add(nn.Dropout(rate=dropout))\n",
        "            self.classifier.add(nn.Dense(units=num_classes))\n",
        "\n",
        "    def forward(self, inputs, token_types, valid_length=None):\n",
        "        _, pooler = self.bert(inputs, token_types, valid_length)\n",
        "        return self.classifier(pooler)\n",
        "                                           "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8Ww6eZ4ZBhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BERTClassifier(bert_base, num_classes=2, dropout=0.3)\n",
        "# 분류 레이어만 초기화 한다. \n",
        "model.classifier.initialize(ctx=ctx)\n",
        "model.hybridize()\n",
        "\n",
        "# softmax cross entropy loss for classification\n",
        "loss_function = gluon.loss.SoftmaxCELoss()\n",
        "\n",
        "metric = mx.metric.Accuracy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w17ckxGIZBjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "lr = 5e-5\n",
        "\n",
        "train_dataloader = mx.gluon.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = mx.gluon.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAUuM4kIZBlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = gluon.Trainer(model.collect_params(), 'bertadam',\n",
        "                        {'learning_rate': lr, 'epsilon': 1e-9, 'wd':0.01})\n",
        "\n",
        "log_interval = 4\n",
        "num_epochs = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI-7BFchZBnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LayerNorm과 Bias에는 Weight Decay를 적용하지 않는다. \n",
        "for _, v in model.collect_params('.*beta|.*gamma|.*bias').items():\n",
        "    v.wd_mult = 0.0\n",
        "params = [\n",
        "    p for p in model.collect_params().values() if p.grad_req != 'null'\n",
        "]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbGc8crUZGoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_accuracy(model, data_iter, ctx=ctx):\n",
        "    acc = mx.metric.Accuracy()\n",
        "    i = 0\n",
        "    for i, (t,v,s, label) in enumerate(data_iter):\n",
        "        token_ids = t.as_in_context(ctx)\n",
        "        valid_length = v.as_in_context(ctx)\n",
        "        segment_ids = s.as_in_context(ctx)\n",
        "        label = label.as_in_context(ctx)\n",
        "        output = model(token_ids, segment_ids, valid_length.astype('float32'))\n",
        "        acc.update(preds=output, labels=label)\n",
        "        if i > 1000:\n",
        "            break\n",
        "        i += 1\n",
        "    return(acc.get()[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MdvTSBnZGqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#learning rate warmup을 위한 준비 \n",
        "step_size = batch_size \n",
        "num_train_examples = len(data_train)\n",
        "num_train_steps = int(num_train_examples / step_size * num_epochs)\n",
        "warmup_ratio = 0.1\n",
        "num_warmup_steps = int(num_train_steps * warmup_ratio)\n",
        "step_num = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyfUWR5DZGsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch_id in range(num_epochs):\n",
        "    metric.reset()\n",
        "    step_loss = 0\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(train_dataloader):\n",
        "        step_num += 1\n",
        "        if step_num < num_warmup_steps:\n",
        "            new_lr = lr * step_num / num_warmup_steps\n",
        "        else:\n",
        "            offset = (step_num - num_warmup_steps) * lr / (\n",
        "                num_train_steps - num_warmup_steps)\n",
        "            new_lr = lr - offset\n",
        "        trainer.set_learning_rate(new_lr)\n",
        "        with mx.autograd.record():\n",
        "            # load data to GPU\n",
        "            token_ids = token_ids.as_in_context(ctx)\n",
        "            valid_length = valid_length.as_in_context(ctx)\n",
        "            segment_ids = segment_ids.as_in_context(ctx)\n",
        "            label = label.as_in_context(ctx)\n",
        "\n",
        "            # forward computation\n",
        "            out = model(token_ids, segment_ids, valid_length.astype('float32'))\n",
        "            ls = loss_function(out, label).mean()\n",
        "\n",
        "        # backward computation\n",
        "        ls.backward()\n",
        "        trainer.allreduce_grads()\n",
        "        nlp.utils.clip_grad_global_norm(params, 1)\n",
        "        trainer.update(token_ids.shape[0])\n",
        "\n",
        "        step_loss += ls.asscalar()\n",
        "        metric.update([label], [out])\n",
        "        if (batch_id + 1) % (50) == 0:\n",
        "            print('[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.10f}, acc={:.3f}'\n",
        "                         .format(epoch_id + 1, batch_id + 1, len(train_dataloader),\n",
        "                                 step_loss / log_interval,\n",
        "                                 trainer.learning_rate, metric.get()[1]))\n",
        "            step_loss = 0\n",
        "    test_acc = evaluate_accuracy(model, test_dataloader, ctx)\n",
        "    print('Test Acc : {}'.format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJGx0uK9ZGtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCrqjCfcZGvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp-F_4sVZGxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5jOwZtfZGza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKu9KBsTZBo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y0EKm6rZBq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Heqkv3VXZBXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIkMizqEZHT9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}