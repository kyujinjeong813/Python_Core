{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST (FFNN 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 784)\n"
     ]
    }
   ],
   "source": [
    "# 128장의 이미지를 random하게 공급 (중복은?!)\n",
    "batch_x, batch_y = mnist.train.next_batch(128)\n",
    "print(batch_x.shape) # flatten된 상태 (784)\n",
    "learning_rate = 0.1 # hyper parameter\n",
    "num_steps = 500 # epoch 세대\n",
    "batch_size = 128 # mini batch 사이즈 : 속도를 고속, 지역해를 극복하기 위해서\n",
    "display_step = 100 # 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "num_input = 784\n",
    "num_classes = 10\n",
    "X = tf.placeholder(\"float\", [None, num_input]) # 128 X 784\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1' : tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2' : tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out' : tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1' : tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2' : tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out' : tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(x):\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = neural_net(X)\n",
    "# 원핫 인코드된 값 * log(확률값)\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "# 최적화기 : 기울기, 학습율\n",
    "# adagrad : learning rate 처음에는 크게 -> 점점 작게\n",
    "# momentum + propgrad : adaptive 적응적으로\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "# 가장 큰 값의 인덱스를 구함 (one-hot-encoding) => target\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y,1))\n",
    "# 데이터 형변환\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss = 13108.4561, Training Accuracy= 0.344\n",
      "Step 100, Minibatch Loss = 268.1597, Training Accuracy= 0.883\n",
      "Step 200, Minibatch Loss = 174.8662, Training Accuracy= 0.852\n",
      "Step 300, Minibatch Loss = 70.8949, Training Accuracy= 0.875\n",
      "Step 400, Minibatch Loss = 30.5856, Training Accuracy= 0.875\n",
      "Step 500, Minibatch Loss = 52.2661, Training Accuracy= 0.859\n",
      "테스트 정확도: 0.8559\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: # GPU 네트워크 연결\n",
    "    sess.run(init)\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_op, feed_dict={X:batch_x, Y:batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            loss, acc = sess.run([loss_op, accuracy],\n",
    "                                feed_dict={X:batch_x, Y:batch_y})\n",
    "            print(\"Step \"+ str(step) + \", Minibatch Loss = \"+ \"{:.4f}\".format(loss) +\n",
    "                 \", Training Accuracy= \" + \"{:.3f}\".format(acc))\n",
    "    print(\"테스트 정확도:\", sess.run(accuracy, feed_dict={X:mnist.test.images, Y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM   ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "501  0.06263  0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527  0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076  0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959  0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741  0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  const  \n",
       "501     21.0  391.99   9.67    1.0  \n",
       "502     21.0  396.90   9.08    1.0  \n",
       "503     21.0  396.90   5.64    1.0  \n",
       "504     21.0  393.45   6.48    1.0  \n",
       "505     21.0  396.90   7.88    1.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['const'] = np.ones(df.shape[0])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = df.shape\n",
    "X = tf.placeholder(tf.float64, shape=(n,m))\n",
    "y = tf.placeholder(tf.float64, shape=(n,1))\n",
    "XT = tf.transpose(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측한 집값 : [18.40613603] 실제 집값 : 18.2\n"
     ]
    }
   ],
   "source": [
    "# 행렬식\n",
    "# 거듭제곱 : 상관계수 506 (data point) * 14 (변수)\n",
    "# 14X506, 506X14 => 14X14 (상관행렬) => 역행렬\n",
    "# 14X14, 14X506 => 14X506\n",
    "# 14X506, 506X1 => 14X1\n",
    "w = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "y_pred = tf.matmul(X, w) # 회귀식 (506X1)\n",
    "with tf.Session() as sess:\n",
    "    y_pred_ = sess.run(y_pred, feed_dict={X:df.values, y:boston.target.reshape(-1,1)})\n",
    "print(\"예측한 집값 :\", y_pred_[19], \"실제 집값 :\", boston.target[19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "홑일 때 [0 2 3 0 2 3 0 2 3 0 2 3 0 2 3]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "val = [0,2,3]\n",
    "val = tf.tile(val, [5])\n",
    "print(\"홑일 때\", sess.run(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2차원일때 [[1 1 1 1 1 1]\n",
      " [2 2 2 2 2 2]\n",
      " [3 3 3 3 3 3]\n",
      " [1 1 1 1 1 1]\n",
      " [2 2 2 2 2 2]\n",
      " [3 3 3 3 3 3]\n",
      " [1 1 1 1 1 1]\n",
      " [2 2 2 2 2 2]\n",
      " [3 3 3 3 3 3]\n",
      " [1 1 1 1 1 1]\n",
      " [2 2 2 2 2 2]\n",
      " [3 3 3 3 3 3]\n",
      " [1 1 1 1 1 1]\n",
      " [2 2 2 2 2 2]\n",
      " [3 3 3 3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "val = [[1,1,1],[2,2,2],[3,3,3]]\n",
    "val = tf.tile(val, [5,2])\n",
    "print(\"2차원일때\", sess.run(val))\n",
    "\n",
    "# tile은 차원을 확대하지는 않음 (차수만 늘어남)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  1.  2.  1.  2.]\n",
      " [ 2.  1.  2.  1.  2.  1.]\n",
      " [-2. -1. -2. -1. -2. -1.]]\n",
      "[[ 1.  2.  1.  2.  1.  2.]\n",
      " [ 2.  1.  2.  1.  2.  1.]\n",
      " [-2. -1. -2. -1. -2. -1.]\n",
      " [ 1.  2.  1.  2.  1.  2.]\n",
      " [ 2.  1.  2.  1.  2.  1.]\n",
      " [-2. -1. -2. -1. -2. -1.]]\n"
     ]
    }
   ],
   "source": [
    "input_vecs = [[1.,2.],[2.,1.],[-2.,-1.]]\n",
    "tiled_vecs = tf.tile(input_vecs, [1,3])\n",
    "print(sess.run(tiled_vecs))\n",
    "tiled_vecs = tf.tile(input_vecs, [2,3])\n",
    "print(sess.run(tiled_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K means : K가 결정 => 중심이 발생\n",
    "- 각 데이터의 중심값을 빼서 거리값을 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import scale\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "iris = datasets.load_iris() # 4개 변수, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pts = len(iris.data) # 행수\n",
    "num_feats = len(iris.data[0]) # 열수\n",
    "k = 3 # 군집수\n",
    "generations = 25 # epoch\n",
    "data_points = tf.Variable(iris.data)\n",
    "cluster_labels = tf.Variable(tf.zeros([num_pts], dtype=tf.int64))\n",
    "rand_starts = np.array([iris.data[np.random.choice(len(iris.data))] for _ in range(k)])\n",
    "centroids = tf.Variable(rand_starts)\n",
    "centroid_matrix = tf.reshape(tf.tile(centroids, [num_pts, 1]),\n",
    "                            [num_pts, k, num_feats])\n",
    "point_matrix = tf.reshape(tf.tile(data_points, [1,k]),\n",
    "                         [num_pts, k, num_feats])\n",
    "distances = tf.reduce_sum(tf.square(point_matrix - centroid_matrix), axis=2)\n",
    "centroid_group = tf.argmin(distances, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_group_avg(group_ids, data):\n",
    "    # 라벨 번호로 값의 합계를 냄\n",
    "    sum_total = tf.unsorted_segment_sum(data, group_ids, 3)\n",
    "    num_total = tf.unsorted_segment_sum(tf.ones_like(data), group_ids, 3)\n",
    "    avg_by_group = sum_total/num_total\n",
    "    return (avg_by_group)\n",
    "means = data_group_avg(centroid_group, data_points)\n",
    "update = tf.group(centroids.assign(means), cluster_labels.assign(centroid_group))\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating gen 0, out of 25\n",
      "Group counts: [55, 50, 45]\n",
      "Calculating gen 1, out of 25\n",
      "Group counts: [57, 50, 43]\n",
      "Calculating gen 2, out of 25\n",
      "Group counts: [60, 50, 40]\n",
      "Calculating gen 3, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 4, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 5, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 6, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 7, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 8, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 9, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 10, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 11, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 12, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 13, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 14, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 15, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 16, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 17, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 18, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 19, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 20, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 21, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 22, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 23, out of 25\n",
      "Group counts: [61, 50, 39]\n",
      "Calculating gen 24, out of 25\n",
      "Group counts: [61, 50, 39]\n"
     ]
    }
   ],
   "source": [
    "for i in range(generations):\n",
    "    print('Calculating gen {}, out of {}'.format(i, generations))\n",
    "    _, centroid_group_count = sess.run([update, centroid_group])\n",
    "    group_count = []\n",
    "    for ix in range(k):\n",
    "        group_count.append(np.sum(centroid_group_count==ix))\n",
    "    print(\"Group counts: {}\".format(group_count))\n",
    "[centers, assignments] = sess.run([centroids, cluster_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "def most_common(my_list):\n",
    "    return(max(set(my_list), key=my_list.count))\n",
    "label0 = most_common(list(assignments[0:50]))\n",
    "label1 = most_common(list(assignments[50:100]))\n",
    "label2 = most_common(list(assignments[100:150]))\n",
    "group0_count = np.sum(assignments[0:50]==label0)\n",
    "group1_count = np.sum(assignments[50:100]==label1)\n",
    "group2_count = np.sum(assignments[100:150]==label2)\n",
    "accuracy = (group0_count + group1_count + group2_count)/150.\n",
    "print('Accuracy: {:.2}'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
